{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Ahmet Yildirim\n",
    "# Date: 13.09.2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_rows=500\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_search(est, p_grid, X_train, y_train, scr, refit, n=2):\n",
    "    cv = StratifiedKFold(n_splits=n, shuffle=True, random_state=1)\n",
    "    return GridSearchCV(estimator=est, param_grid=p_grid, scoring=scr, n_jobs=1, cv=cv, verbose=0, refit=refit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nested_score(est, X_train, y_train, scr, n=5):\n",
    "    cv = StratifiedKFold(n_splits=n, shuffle=True, random_state=1)\n",
    "    nested_score = pd.DataFrame(cross_validate(est, X=X_train, y=y_train, cv=cv, n_jobs=1, scoring=scr, return_train_score=True))\n",
    "    return {'mean_score': nested_score.mean().to_dict(), 'std_score':nested_score.std().to_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(est_dict, X_train, y_train, scr, n=5):\n",
    "    return {name: compute_nested_score(est, X_train, y_train, scr, n) for name, est in est_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and splitting the dataset\n",
    "dataset = load_iris()\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimators\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='newton-cg', random_state=1)\n",
    "knn = KNeighborsClassifier(algorithm='ball_tree', leaf_size=50)\n",
    "svm = SVC(random_state=1)\n",
    "\n",
    "# Parameter Grids for Estimators\n",
    "p_grid_logreg = [{'penalty': ['l2'],\n",
    "              'C': np.power(10., np.arange(-4, 4))}]\n",
    "\n",
    "p_grid_knn = [{'n_neighbors': list(range(1, 10)),\n",
    "               'p': [1, 2]}]\n",
    "\n",
    "p_grid_svm = [{'kernel': ['rbf'],\n",
    "              'C': np.power(10., np.arange(-4, 4)),\n",
    "              'gamma': np.power(10., np.arange(-5, 0))},\n",
    "             {'kernel': ['linear'],\n",
    "              'C': np.power(10., np.arange(-4, 4))}]\n",
    "\n",
    "# Estimator List and Parameter Grid List\n",
    "est_names = ['LogisticRegression', 'KNN', 'SVM']\n",
    "est_list = [logreg, knn, svm]\n",
    "p_grid_list = [p_grid_logreg, p_grid_knn, p_grid_svm]\n",
    "\n",
    "scoring = {'accuracy': 'accuracy'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator dictionary with tuned parameters\n",
    "grid_search_dict = {name: create_grid_search(est, p_grid, X_train, y_train, scr='accuracy', refit='accuracy', n=2) for name, est, p_grid in zip(est_names, est_list, p_grid_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of estimators with tuned parameters\n",
    "result = compare_models(grid_search_dict, X_train, y_train, scr=scoring, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">mean_score</th>\n",
       "      <th colspan=\"4\" halign=\"left\">std_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>0</th>\n",
       "      <td>0.121391</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.023292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>0</th>\n",
       "      <td>0.303104</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.972917</td>\n",
       "      <td>0.034667</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.047507</td>\n",
       "      <td>0.011877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>0</th>\n",
       "      <td>0.131478</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.977083</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.017116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean_score                                          \\\n",
       "                       fit_time score_time test_accuracy train_accuracy   \n",
       "KNN                0   0.121391   0.000950      0.966667       0.968750   \n",
       "LogisticRegression 0   0.303104   0.000191      0.941667       0.972917   \n",
       "SVM                0   0.131478   0.000250      0.966667       0.977083   \n",
       "\n",
       "                     std_score                                          \n",
       "                      fit_time score_time test_accuracy train_accuracy  \n",
       "KNN                0  0.006577   0.000014      0.034861       0.023292  \n",
       "LogisticRegression 0  0.034667   0.000020      0.047507       0.011877  \n",
       "SVM                0  0.015450   0.000082      0.034861       0.017116  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result of estimator comparison in terms of roc_auc\n",
    "pd.concat({k: pd.DataFrame(v).unstack().to_frame().T for k, v in result.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_algo = grid_search_dict['SVM']\n",
    "best_algo.fit(X_train, y_train)\n",
    "best_params = best_algo.best_params_\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 98.33 (average over CV test folds)\n",
      "Best Parameters: {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Training Accuracy: 97.50\n",
      "Test Accuracy: 96.67\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy {0:.2f} (average over CV test folds)'.format(100 * best_algo.best_score_))\n",
    "print('Best Parameters: {}'.format(best_params))\n",
    "print('Training Accuracy: {0:.2f}'.format(100 * train_acc))\n",
    "print('Test Accuracy: {0:.2f}'.format(100 * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
